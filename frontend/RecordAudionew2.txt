<template>
    <div>
        <h2>Audio Recorder</h2>
        <main>
            <div>Permission: {{ permission }}</div>
            <div>Recording status: {{ recordingStatus }}</div>
            <div className="audio-controls">
                <button v-if="!permission" @click=getMicrophonePermission() type="button">
                    Get Microphone
                </button>
                <button v-if="permission && !recordingStatus" @click="startRecording()" type="button">
                    Start Recording
                </button>
                <button v-show="recordingStatus" @click="stopRecording()" type="button">
                    Stop Recording
                </button>
            </div>
            <div v-if="audioUrl" className="audio-player">
<!--            <div v-if="audioUrl" className="audio-player">-->
                <audio id="recorded_audio" controls autoplay>
                    <source :src="audioUrl" :type="mimeType">
                </audio>
                <p>
                    <a download :href="audioUrl" :type="mimeType">
                        Download Recording
                    </a>
                </p>
                <p>Link: {{ audioUrl }}</p>
                <p>mime-type: {{ mimeType }}</p>
                <p>Text: {{ transcribedText }}</p>
            </div>
        </main>
    </div>
</template>


<script setup>

import {ref} from "vue";
import {StartStreamTranscriptionCommand, TranscribeStreamingClient} from "@aws-sdk/client-transcribe-streaming";
import MicrophoneStream from "microphone-stream";
// import mic from "microphone-stream";

let stream;
let audioChunks = [];

let audioMime = {
    mimeType: 'audio/webm',
    // numberOfAudioChannels: 2,
    audioBitsPerSecond: 16000,
}

const mediaRecorder = ref();
const permission = ref(false);
const recordingStatus = ref(false);
const audioUrl = ref("");
const mimeType = ref(audioMime.mimeType);
let transcribedText = ref("");
let transcribeClient;
let credentials;

const micStream = new MicrophoneStream();

const region = 'us-east-1';
// const region = process.env.VUE_APP_AWS_REGION;

getTranscribeCredentials();

// const credentials = await getTranscribeCredentials()
//     .then(response => {return response.json()})
//     .then(data => {return data});

// eslint-disable-next-line no-undef
defineExpose({
    permission,
    recordingStatus,
    audioUrl,
    mimeType
})

// eslint-disable-next-line no-unused-vars
async function getMicrophonePermission() {
    // credentials = await getTranscribeCredentials().then();



    if ("MediaRecorder" in window) {
        try {
            const mediaStream = await navigator.mediaDevices.getUserMedia({
                audio: true,
                video: false,
            });
            permission.value = true;
            console.log("permission ", permission.value);
            console.log("recording status ", recordingStatus.value);
            stream = mediaStream;
        } catch (err) {
            alert(err.message);
        }
    } else {
        alert("The MediaRecorder API is not supported in your browser.");
    }


    // const micStream = new MicrophoneStream();

    // micStream.setStream(
    //     await window.navigator.mediaDevices.getUserMedia({
    //         video: false,
    //         audio: true,
    //     })
    // );

    micStream.setStream(stream);


}



// const input = { // StartStreamTranscriptionRequest
//     LanguageCode: "en-US",
//     MediaSampleRateHertz: Number(16000),
//     MediaEncoding: "pcm", // "pcm" || "ogg-opus" || "flac"
//     AudioStream: {
//         AudioEvent: {
//             AudioChunk: "BLOB_VALUE"
//         }
//     }
// }
//
// const command = new StartStreamTranscriptionCommand(input);
// const response = await transcribeClient.send(command);


// async function startRecording() {
//     console.log("credentials: ", credentials);
//     transcribeClient = new TranscribeStreamingClient({
//         region,
//         credentials
//     });
//     recordingStatus.value = true;
//
//     // get Buffers (Essentially a Uint8Array DataView of the same Float32 values)
//     micStream.on('data', function(chunk) {
//         // Optionally convert the Buffer back into a Float32Array
//         // (This actually just creates a new DataView - the underlying audio data is not copied or modified.)
//         const raw = MicrophoneStream.toRaw(chunk);
//         //...
//
//         // note: if you set options.objectMode=true, the `data` event will output AudioBuffers instead of Buffers
//     });
//
// }
// eslint-disable-next-line no-unused-vars
async function startRecording() {
    console.log("credentials: ", credentials);
    transcribeClient = new TranscribeStreamingClient({
        region,
        credentials
    });
    recordingStatus.value = true;


    // const audioStream = async function* () {
    //     for await (const chunk of micStream) {
    //         yield { AudioEvent: { AudioChunk: chunk /* pcm Encoding is optional depending on the source */ } };
    //         // yield { AudioEvent: { AudioChunk: pcmEncodeChunk(chunk) /* pcm Encoding is optional depending on the source */ } };
    //     }
    // };

    mediaRecorder.value = new MediaRecorder(stream, audioMime);
    mediaRecorder.value.start();
    //
    // // let localAudioChunks = [];
    //
    mediaRecorder.value.ondataavailable = async (event) => {
        if (typeof event.data === "undefined") return;
        if (event.data.size === 0) return;
        // localAudioChunks.push(event.data);
        audioChunks.push(event.data);
    }

    micStream.on('data', async function(chunk) {
        // Optionally convert the Buffer back into a Float32Array
        // (This actually just creates a new DataView - the underlying audio data is not copied or modified.)
       // const raw = MicrophoneStream.toRaw(chunk);
        //...

        const input = { // StartStreamTranscriptionRequest
            LanguageCode: "en-US",
            MediaSampleRateHertz: Number(16000),
            // MediaEncoding: "pcm", // "pcm" || "ogg-opus" || "flac"
            MediaEncoding: "pcm", // "pcm" || "ogg-opus" || "flac"
            AudioStream: {
                AudioEvent: {
                    AudioChunk: chunk
                }
            }
            // AudioStream: audioStream()
                    // AudioChunk: convertAudioToBinaryMessage(chunk)
                    // AudioChunk: event.data
        }

        const command = new StartStreamTranscriptionCommand(input);
        transcribedText.value = await transcribeClient.send(command);

        // micStream.on('data', function(rawAudioChunk) {
        //     console.log("received data from mic ...")
        //     // the audio stream is raw audio bytes. Transcribe expects PCM with additional metadata, encoded as binary
        //     let binary = convertAudioToBinaryMessage(rawAudioChunk);
        //
        // }
        // note: if you set options.objectMode=true, the `data` event will output AudioBuffers instead of Buffers
    // });

    // const media = new MediaRecorder(stream, audioMime);
    // mediaRecorder.value = new MediaRecorder(stream, audioMime);
    // mediaRecorder.value.start();
    // //
    // // // let localAudioChunks = [];
    // //
    // mediaRecorder.value.ondataavailable = async (event) => {
    //     if (typeof event.data === "undefined") return;
    //     if (event.data.size === 0) return;
    //     // localAudioChunks.push(event.data);
    //     audioChunks.push(event.data);
    // }
    // setAudioChunks(localAudioChunks);
});
}

// eslint-disable-next-line no-unused-vars
async function stopRecording() {
    recordingStatus.value = false;
    mediaRecorder.value.stop();

    mediaRecorder.value.onstop = () => {
        const audioBlob = new Blob(audioChunks, audioMime);
        audioUrl.value = URL.createObjectURL(audioBlob);
        // + "." + audioMime.mimeType.substring(audioMime.mimeType.lastIndexOf("/") + 1);
        console.log("audioURL: ", audioUrl.value);
        // setAudio(audioUrl);

        audioChunks = [];
        // setAudioChunks([]);
        // let recordedAudio = document.getElementById("recorded_audio");
        // console.log("recorded audio :", recordedAudio);
        // recordedAudio.play();

        console.log("transcribe response: ", transcribedText.value);

    }
}

async function getTranscribeCredentials() {
    // const getCredentialsUrl = process.env.VUE_APP_BACKEND_PROTOCOL + "://" + process.env.VUE_APP_BACKEND_HOST + '/api/v1/sts';
    const getCredentialsUrl = "http://localhost:9090/api/v1/sts";
    await fetch(getCredentialsUrl, {method: "POST"}).then(response => {
        if (!response.ok) {
            const message = `An error has occurred: ${response.status}`;
            throw new Error(message);
        }
        return response.json()
    }).then(data => {
        console.log("STS response: ", data);
        credentials = data;
        return data;
    });
}

// function convertAudioToBinaryMessage(audioChunk) {
//     let raw = mic.toRaw(audioChunk);
//
//     if (raw == null)
//         return;
//
//     // downsample and convert the raw audio bytes to PCM
//     let downsampledBuffer = audioUtils.downsampleBuffer(raw, inputSampleRate, sampleRate);
//     let pcmEncodedBuffer = audioUtils.pcmEncode(downsampledBuffer);
//
//     // add the right JSON headers and structure to the message
//     let audioEventMessage = getAudioEventMessage(Buffer.from(pcmEncodedBuffer));
//
//     //convert the JSON object + headers into a binary event stream message
//     let binary = eventStreamMarshaller.marshall(audioEventMessage);
//
//     return binary;
// }

// const AudioRecorder = () => {
//   const [permission, setPermission] = useState(false);
//
//   const mediaRecorder = useRef(null);
//
//   const [recordingStatus, setRecordingStatus] = useState("inactive");
//
//   const [stream, setStream] = useState(null);
//
//   const [audio, setAudio] = useState(null);
//
//   const [audioChunks, setAudioChunks] = useState([]);

// async function getMicrophonePermission() {
//   if ("MediaRecorder" in window) {
//     try {
//       const mediaStream = await navigator.mediaDevices.getUserMedia({
//         audio: true,
//         video: false,
//       });
//       setPermission(true);
//       setStream(mediaStream);
//     } catch (err) {
//       alert(err.message);
//     }
//   } else {
//     alert("The MediaRecorder API is not supported in your browser.");
//   }
// }

// const startRecording = async () => {
//   setRecordingStatus("recording");
//   const media = new MediaRecorder(stream, {type: mimeType});
//
//   mediaRecorder.current = media;
//
//   mediaRecorder.current.start();
//
//   let localAudioChunks = [];
//
//   mediaRecorder.current.ondataavailable = (event) => {
//     if (typeof event.data === "undefined") return;
//     if (event.data.size === 0) return;
//     localAudioChunks.push(event.data);
//   }
//
//   setAudioChunks(localAudioChunks);
// }

// const stopRecording = () => {
//   setRecordingStatus("inactive");
//   mediaRecorder.current.stop();
//
//   mediaRecorder.current.onstop = () => {
//     const audioBlob = new Blob(audioChunks, {type: mimeType});
//     const audioUrl = URL.createObjectURL(audioBlob);
//
//     setAudio(audioUrl);
//
//     setAudioChunks([]);
//   }
// }

</script>


<style scoped lang="css">
</style>